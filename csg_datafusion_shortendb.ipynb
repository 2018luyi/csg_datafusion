{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Database Shortener\n",
    "By Stephen Larroque @ Coma Science Group, GIGA Research, University of Liege\n",
    "Creation date: 2017-04-05\n",
    "License: MIT\n",
    "v1.2.0\n",
    "2017-2019\n",
    "\n",
    "## INSTALL NOTE:\n",
    "You need to pip install pandas before launching this script.\n",
    "Tested on Python 2.7.15\n",
    "\n",
    "## DESCRIPTION:\n",
    "Extracts a subset of rows from a csv database based on a list of names provided in a second csv file. In other words, we keep from the reference database only the records that have an id that can be found in the filter database.\n",
    "You have two csv files: one being the full database full of demographics infos, the other one being the list of patients names for your study.\n",
    "If you want to filter the full database to extract only the patients in your smaller list, then use this notebook.\n",
    "\n",
    "## USAGE:\n",
    "Any two csv files can be used for the shortening, you just need to have a \"name\" field in both. The first csv will be used as the reference, and its rows will be extracted if same names are found in the second database.\n",
    "\n",
    "## TODO:\n",
    "* Nothing here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcefully autoreload all python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUX FUNCTIONS\n",
    "\n",
    "import os, sys\n",
    "\n",
    "cur_path = os.path.realpath('.')\n",
    "sys.path.append(os.path.join(cur_path, 'csg_fileutil_libs'))  # for unidecode and cleanup_name, because it does not support relative paths (yet?)\n",
    "\n",
    "import re\n",
    "\n",
    "from csg_fileutil_libs.aux_funcs import compute_names_distance_matrix, cleanup_name, cleanup_name_df, cleanup_name_customregex_df, replace_buggy_accents, save_df_as_csv, _tqdm, df_to_unicode, df_to_unicode_fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# Reference database, from which records will be extracted (need to include a \"name\" column with all the patients names)\n",
    "ref_db = r'databases_output\\fmp_db_subjects_aggregated.csv_etiosedatfixed_dicomsdatediag_dicompathsedat.csv_acute.csv'\n",
    "ref_db_idcol = 'Name'  # id column name for the reference database\n",
    "\n",
    "# Filter database, the one used to filter the reference database's records by matching names (need to include a \"name\" column with all the patients names)\n",
    "filt_db = r'databases_original\\CSG_demographics_QC_2_final 36 subjects_FOR_Stephen (ENCRYPTED).csv'\n",
    "filt_db_idcol = 'name'   # id column name for the filter database (both databases will be joined on this key and then filtered)\n",
    "\n",
    "# Output where to store the CSV files\n",
    "output_dir = r'databases_output'\n",
    "\n",
    "# How to filter names in the filter database (remove useless terms) - can use regex\n",
    "filter_name = {'_': ' ',\n",
    "               'repos': '',\n",
    "               'ecg': '',\n",
    "               '[0-9]+': '',\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "# Loading databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load reference database\n",
    "cref = pd.read_csv(ref_db, sep=';')\n",
    "cref.dropna(axis=0, subset=[ref_db_idcol], inplace=True) # drop lines where the name is empty, important to avoid errors\n",
    "# Clean up names in full/reference database (to more easily compare)\n",
    "cref[ref_db_idcol+'_orig'] = cref[ref_db_idcol]  # make a backup first\n",
    "cref = cleanup_name_df(cref, col=ref_db_idcol)\n",
    "# Show\n",
    "cref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filter database\n",
    "cfilt = pd.read_csv(filt_db, sep=';').dropna(how='all').dropna(subset=[filt_db_idcol], how='all')\n",
    "# Reorder by name\n",
    "cfilt.sort_values(filt_db_idcol, inplace=True)\n",
    "# Removing useless terms from the patient name\n",
    "if filter_name:\n",
    "    cfilt = cleanup_name_customregex_df(cfilt, filter_name)\n",
    "# Cleanup name in filtering db\n",
    "cfilt = cleanup_name_df(cfilt, col=filt_db_idcol)\n",
    "# Print db\n",
    "print(\"Filter database contains %i rows.\" % len(cfilt))\n",
    "cfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: number of subjects in the filter database with missing id/name (they will be dropped, we need an id to filter!)\n",
    "missing_id = cfilt[filt_db_idcol].isnull() | (cfilt[filt_db_idcol] == '')\n",
    "print('Filter database contains %i rows with a missing id/name, they will be dropped.' % sum(missing_id))\n",
    "cfilt[missing_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "## Comparison of the two csv databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging parameters - EDIT ME - do not hesitate to try different parameters until the matching seems good to you\n",
    "dist_threshold_letters = 0.2 # percentage of letters matching\n",
    "dist_threshold_words = 0.4 # percentage of words matching\n",
    "dist_threshold_words_norm = True # normalize words jaccard distance? Can be True, False or None\n",
    "dist_minlength = 4 # minimum length of words to compare distance jaccard words\n",
    "\n",
    "# Merge the two databases names\n",
    "dmat = compute_names_distance_matrix(cfilt[filt_db_idcol], cref[ref_db_idcol], dist_threshold_letters, dist_threshold_words, dist_threshold_words_norm, dist_minlength)\n",
    "print('Reference & Filter databases were merged successfully!')\n",
    "print('List of matchs (please check if this looks fine!):')\n",
    "dmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the list of names found in the filter database but missing in the reference database\n",
    "missing_list = [key for key, val in dmat.items() if val is None]\n",
    "cmissing = pd.DataFrame(missing_list, columns=[ref_db_idcol])\n",
    "#cmissing.to_csv(os.path.join(output_dir, 'shorten_missing.csv'), index=False, sep=';')\n",
    "save_df_as_csv(df_to_unicode_fast(cmissing), os.path.join(output_dir, 'shorten_missing.csv'), fields_order=False, keep_index=False)\n",
    "print('Saved list of missing subjects in shorten_missing.csv')\n",
    "print('Missing subjects (no demographics found in the reference database): %i' % len(missing_list))\n",
    "cmissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten (filter) reference demographics database\n",
    "# In other words, we keep from the reference database only the records that have an id that can be found in the filter database\n",
    "found_list = [item[0] for item in filter(None, dmat.values())]\n",
    "cfound = cref[cref[ref_db_idcol].isin(found_list)]\n",
    "\n",
    "# Add a column to show what was the filtering name\n",
    "dmat_inv = {ref_db_idcol: [], (ref_db_idcol+'_filter'): []}\n",
    "for key, vals in dmat.items():\n",
    "    if vals is None:\n",
    "        continue\n",
    "    for v in vals:\n",
    "        dmat_inv[ref_db_idcol].append(v)\n",
    "        dmat_inv[ref_db_idcol+'_filter'].append(key)\n",
    "# create a dataframe\n",
    "df_dmat_inv = pd.DataFrame(dmat_inv)\n",
    "df_dmat_inv[ref_db_idcol] = df_dmat_inv[ref_db_idcol].apply(str)\n",
    "# merge on name column\n",
    "cfound2 = pd.merge(cfound, df_dmat_inv, how='outer', on=ref_db_idcol)\n",
    "# reorder columns to place name_filter just after name\n",
    "cfound2 = cfound2[cfound2.columns[[0, -1] + range(1,len(cfound2.columns)-1)]]\n",
    "# Restore original name (without cleanup)\n",
    "cfound2[ref_db_idcol+'_clean'] = cfound2[ref_db_idcol]  # make a backup of the cleaned up name first, so that we can easily compare and understand how the filtering worked\n",
    "cfound2[ref_db_idcol] = cfound2[ref_db_idcol+'_orig']  # restore the original names\n",
    "# reorder columns to place name_orig just after name\n",
    "cfound2 = cfound2[cfound2.columns[[0, -1] + range(1,len(cfound2.columns)-1)]]\n",
    "\n",
    "# Save into a csv file\n",
    "#cfound2.to_csv(os.path.join(output_dir, 'shorten_found.csv'), index=False, sep=';')\n",
    "save_df_as_csv(df_to_unicode_fast(cfound2), os.path.join(output_dir, 'shorten_found.csv'), fields_order=False, keep_index=False, blankna=True)\n",
    "print('Saved list of found subjects in shorten_found.csv')\n",
    "print('Found subjects: %i' % len(found_list))\n",
    "cfound2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csg_fileutil_libs.distance import distance\n",
    "from csg_fileutil_libs.aux_funcs import distance_jaccard_words_split\n",
    "\n",
    "subj = 'de caliafiera'\n",
    "c = 'de caliafiera teng'\n",
    "print(distance.nlevenshtein(subj, c, method=1))\n",
    "print(distance_jaccard_words_split(subj, c, partial=True, norm=None, dist=dist_threshold_letters, minlength=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
