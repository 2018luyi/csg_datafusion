{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Database Shortener\n",
    "# By Stephen Larroque @ Coma Science Group, GIGA Research, University of Liege\n",
    "# Creation date: 2017-04-05\n",
    "# License: MIT\n",
    "# v1.1.0\n",
    "# INSTALL NOTE:\n",
    "# You need to pip install pandas before launching this script.\n",
    "# Tested on Python 2.7.13\n",
    "#\n",
    "# DESCRIPTION:\n",
    "# Extracts a subset of rows from a csv database based on a list of names provided in a second csv file.\n",
    "# You have two csv files: one being the full database full of demographics infos, the other one being the list of patients names for your study.\n",
    "# If you want to filter the full database to extract only the patients in your smaller list, then use this notebook.\n",
    "#\n",
    "# USAGE:\n",
    "# Any two csv files can be used for the shortening, you just need to have a \"name\" field in both. The first csv will be used as the reference, and its rows will be extracted if same names are found in the second database.\n",
    "#\n",
    "# TODO:\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcefully autoreload all python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUX FUNCTIONS\n",
    "\n",
    "import os, sys\n",
    "\n",
    "cur_path = os.path.realpath('.')\n",
    "sys.path.append(os.path.join(cur_path, 'csg_fileutil_libs'))  # for unidecode and cleanup_name, because it does not support relative paths (yet?)\n",
    "\n",
    "import re\n",
    "\n",
    "from csg_fileutil_libs.aux_funcs import compute_names_distance_matrix, cleanup_name, cleanup_name_df, cleanup_name_customregex_df, replace_buggy_accents, save_df_as_csv, _tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# Reference database, from which records will be extracted (need to include a \"name\" column with all the patients names)\n",
    "ref_db = r'latestdbs2018\\fmp_db_subjects_aggregated.csv_etiosedatfixed_dicomsdatediag.csv_acute_mergesedat_sedatmine - Copie.csv'\n",
    "\n",
    "# Filter database, the one used to filter the reference database's records by matching names (need to include a \"name\" column with all the patients names)\n",
    "filt_db = r'latestdbs2018\\CSG_demographics_QC_2_final 36 subjects_FOR_Stephen.csv'\n",
    "\n",
    "# How to filter names in the filter database (remove useless terms) - can use regex\n",
    "filter_name = {'_': ' ',\n",
    "               'repos': '',\n",
    "               'ecg': '',\n",
    "               '[0-9]+': '',\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "# Loading databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cref = pd.read_csv(ref_db, sep=';')\n",
    "cref.dropna(axis=0, subset=['name'], inplace=True) # drop lines where the name is empty, important to avoid errors\n",
    "cref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfilt = pd.read_csv(filt_db, sep=';').dropna(how='all').dropna(subset=['name'], how='all')\n",
    "# Reorder by name\n",
    "cfilt.sort_values('name', inplace=True)\n",
    "# Removing useless terms from the patient name\n",
    "if filter_name:\n",
    "    cfilt = cleanup_name_customregex_df(cfilt, filter_name)\n",
    "# Cleanup name in filtering db\n",
    "cfilt = cleanup_name_df(cfilt)\n",
    "# Clean up names in full database\n",
    "cref = cleanup_name_df(cref)\n",
    "# Print db\n",
    "print(len(cfilt))\n",
    "cfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "## Comparison of the two csv databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging parameters - EDIT ME - do not hesitate to try different parameters until the matching seems good to you\n",
    "dist_threshold_letters = 0.2 # percentage of letters matching\n",
    "dist_threshold_words = 0.4 # percentage of words matching\n",
    "dist_threshold_words_norm = True # normalize words jaccard distance? Can be True, False or None\n",
    "dist_minlength = 4 # minimum length of words to compare distance jaccard words\n",
    "\n",
    "# Merge the two databases names\n",
    "dmat = compute_names_distance_matrix(cfilt['name'], cref['name'], dist_threshold_letters, dist_threshold_words, dist_threshold_words_norm, dist_minlength)\n",
    "print('Reference & Filter databases were merged successfully!')\n",
    "print('List of matchs (please check if this looks fine!):')\n",
    "dmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_list = [key for key, val in dmat.items() if val is None]\n",
    "cmissing = pd.DataFrame(missing_list, columns=['name'])\n",
    "cmissing.to_csv('shorten_missing.csv', index=False, sep=';')\n",
    "print('Saved list of missing subjects in shorten_missing.csv')\n",
    "print('Missing subjects (no demographics found in the reference database): %i' % len(missing_list))\n",
    "cmissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten reference demographics database\n",
    "found_list = [item[0] for item in filter(None, dmat.values())]\n",
    "cfound = cref[cref['name'].isin(found_list)]\n",
    "\n",
    "# Add a column to show what was the filtering name\n",
    "dmat_inv = {'name': [], 'name_filter': []}\n",
    "for key, vals in dmat.items():\n",
    "    for v in vals:\n",
    "        dmat_inv['name'].append(v)\n",
    "        dmat_inv['name_filter'].append(key)\n",
    "# create a dataframe\n",
    "df_dmat_inv = pd.DataFrame(dmat_inv)\n",
    "df_dmat_inv['name'] = df_dmat_inv['name'].apply(str)\n",
    "# merge on name column\n",
    "cfound2 = pd.merge(cfound, df_dmat_inv, how='outer', on='name')\n",
    "# reorder columns to place name_filter just after name\n",
    "cfound2 = cfound2[cfound2.columns[[0, -1] + range(1,len(cfound2.columns)-1)]]\n",
    "\n",
    "# Save into a csv file\n",
    "cfound2.to_csv('shorten_found.csv', index=False, sep=';')\n",
    "print('Saved list of found subjects in shorten_found.csv')\n",
    "print('Found subjects: %i' % len(found_list))\n",
    "cfound2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csg_fileutil_libs.distance import distance\n",
    "from csg_fileutil_libs.aux_funcs import distance_jaccard_words_split\n",
    "\n",
    "subj = 'de caliafiera'\n",
    "c = 'de caliafiera teng'\n",
    "print(distance.nlevenshtein(subj, c, method=1))\n",
    "print(distance_jaccard_words_split(subj, c, partial=True, norm=None, dist=dist_threshold_letters, minlength=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
