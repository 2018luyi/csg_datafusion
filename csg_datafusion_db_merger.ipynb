{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Databases Merger\n",
    "By Stephen Karl Larroque @ Coma Science Group, GIGA Research, University of Liege\n",
    "Creation date: 2018-05-27\n",
    "License: MIT\n",
    "v1.4.7\n",
    "2018-2019\n",
    "\n",
    "DESCRIPTION:\n",
    "Generic tool to merge two CSV databases based on the subject's name (hence expecting a column 'name' in each csv file).\n",
    "This script will take care of fuzzy matching names and append all columns of each csv file, hence centralizing all informations into one file.\n",
    "\n",
    "Note: in case of multiple names/lines matching, they will all be concatenated into a single line: if one name in one of the two databases match multiple names/lines of the second database, then the second databases lines will be concatenated into one. In the opposite case (second database's name match multiple names in first database), the same holds.\n",
    "\n",
    "Note2: please only run one of the PARAMETERS cells at a time (this selects appropriate parameters for the merge), and please follow the order.\n",
    "\n",
    "INSTALL NOTE:\n",
    "You need to pip install pandas before launching this script.\n",
    "Tested on Python 2.7.15\n",
    "\n",
    "USAGE:\n",
    "\n",
    "TODO:\n",
    "* Nothing here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcefully autoreload all python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUX FUNCTIONS\n",
    "\n",
    "import os, sys\n",
    "\n",
    "cur_path = os.path.realpath('.')\n",
    "sys.path.append(os.path.join(cur_path, 'csg_fileutil_libs'))  # for unidecode and cleanup_name, because it does not support relative paths (yet?)\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict\n",
    "from csg_fileutil_libs.aux_funcs import save_df_as_csv, _tqdm, merge_two_df, df_remap_names, concat_vals, df_literal_eval, df_to_unicode, df_to_unicode_fast, reorder_cols_df, df_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_original\\patients-sedation-2018-checked-by-Stephen-from-archives_v7_2018-10-18_full-names-merged.csv'\n",
    "id_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_output\\fmp_db_subjects_aggregated.csv_etiosedatfixed_dicomsdatediag_dicompathsedat.csv_acute.csv'\n",
    "ref_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_fmp_steph.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['steph.', 'fmpagg.']  # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "blankna = False  # blank null values when saving to csv? This improves readability but the dates and numbers can't be reformatted then.\n",
    "columns_order_first = None  # put these columns first when saving in a csv file. If None, no reordering will be done (except that the key columns will be first). Reordering columns (by cut/paste) might lead to losing some columns, so it is better to do it here programmatically.\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "#id_db_keys = None\n",
    "#ref_db_keys = None\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper)', 'datetime|%d/%m/%Y')])\n",
    "ref_db_keys = OrderedDict([('name', 'id'), ('Dicom Date Sync With CRS-R', 'datetime|%Y-%m-%d')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = True  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n",
    "fillna_exclude = None  # allow to exclude some columns from being filled when fillna=True, this is useful particularly for datetime columns\n",
    "join_on_shared_keys = False  # allow the merge on multi-columns to join on only the columns that are shared, this is useful when you want to groupby differently between dataframes (eg, first dataframe with name and date, the second with name only) but you want to keep all rows (else if you join on only name for example, all date rows will be concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR 2ND MERGE (skip this cell if you did not do the first merge beforehand)\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_output\\merged_fmp_steph.csv'\n",
    "id_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_original\\manon_Database_MRI_patients.csv'\n",
    "ref_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_fmp_steph_manon.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['', 'manon.'] # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "blankna = False  # blank null values when saving to csv? This improves readability but the dates and numbers can't be reformatted then.\n",
    "columns_order_first = None  # put these columns first. If None, no reordering will be done (except that the key columns will be first).\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper) + Dicom Date Sync With CRS-R', 'datetime|%Y-%m-%d')])\n",
    "ref_db_keys = OrderedDict([('name', 'id'), ('Date of RMN', 'datetime|%d/%m/%Y')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = True  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n",
    "fillna_exclude = ['MRI date (on mri paper)', 'Dicom Date Sync With CRS-R']  # allow to exclude some columns from being filled when fillna=True, this is useful particularly for datetime columns\n",
    "join_on_shared_keys = False  # allow the merge on multi-columns to join on only the columns that are shared, this is useful when you want to groupby differently between dataframes (eg, first dataframe with name and date, the second with name only) but you want to keep all rows (else if you join on only name for example, all date rows will be concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR 3RD MERGE (skip this cell if you did not do the first merge beforehand)\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_output\\merged_fmp_steph_manon.csv'\n",
    "id_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_output\\SarahBDD_crsr_all.csv'\n",
    "ref_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_fmp_steph_manon_sarah.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['', 'sarah.'] # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "blankna = False  # blank null values when saving to csv? This improves readability but the dates and numbers can't be reformatted then.\n",
    "columns_order_first = None  # put these columns first. If None, no reordering will be done (except that the key columns will be first).\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper) + Dicom Date Sync With CRS-R + Date of RMN', 'datetime|%Y-%m-%d')])\n",
    "ref_db_keys = OrderedDict([('name', 'id'), ('date_assess', 'datetime|%Y-%m-%d')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = False  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n",
    "fillna_exclude = ['MRI date (on mri paper)', 'Dicom Date Sync With CRS-R', 'Date of RMN']  # allow to exclude some columns from being filled when fillna=True, this is useful particularly for datetime columns\n",
    "join_on_shared_keys = False  # allow the merge on multi-columns to join on only the columns that are shared, this is useful when you want to groupby differently between dataframes (eg, first dataframe with name and date, the second with name only) but you want to keep all rows (else if you join on only name for example, all date rows will be concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR 4TH MERGE (skip this cell if you did not do the first merge beforehand)\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_output\\merged_fmp_steph_manon_sarah.csv'\n",
    "id_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_output\\dicoms_db_infosmatch_reorg.csv'\n",
    "ref_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_fmp_steph_manon_sarah_dicom.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['', 'dicom.'] # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "blankna = False  # blank null values when saving to csv? This improves readability but the dates and numbers can't be reformatted then.\n",
    "columns_order_first = None  # put these columns first. If None, no reordering will be done (except that the key columns will be first).\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper) + Dicom Date Sync With CRS-R + Date of RMN + date_assess', 'datetime|%Y-%m-%d')])\n",
    "ref_db_keys = OrderedDict([('name', 'id'), ('StudyDate', 'datetime|{%Y%m%d}')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = False  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n",
    "fillna_exclude = ['MRI date (on mri paper)', 'Dicom Date Sync With CRS-R', 'Date of RMN', 'date_assess']  # allow to exclude some columns from being filled when fillna=True, this is useful particularly for datetime columns\n",
    "join_on_shared_keys = False  # allow the merge on multi-columns to join on only the columns that are shared, this is useful when you want to groupby differently between dataframes (eg, first dataframe with name and date, the second with name only) but you want to keep all rows (else if you join on only name for example, all date rows will be concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR 5TH MERGE (skip this cell if you did not do the first merge beforehand)\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_output\\merged_fmp_steph_manon_sarah_dicom.csv'\n",
    "id_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_output\\ecg_subjects.csv'\n",
    "ref_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_fmp_steph_manon_sarah_dicom_ecg.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['', 'ecg.'] # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "blankna = False  # blank null values when saving to csv? This improves readability but the dates and numbers can't be reformatted then.\n",
    "columns_order_first = None  # put these columns first. If None, no reordering will be done (except that the key columns will be first).\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper) + Dicom Date Sync With CRS-R + Date of RMN + date_assess + StudyDate', 'datetime|%Y-%m-%d')])\n",
    "ref_db_keys = OrderedDict([('name', 'id')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = True  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n",
    "fillna_exclude = ['MRI date (on mri paper)', 'Dicom Date Sync With CRS-R', 'Date of RMN', 'date_assess', 'StudyDate']  # allow to exclude some columns from being filled when fillna=True, this is useful particularly for datetime columns\n",
    "join_on_shared_keys = True  # allow the merge on multi-columns to join on only the columns that are shared, this is useful when you want to groupby differently between dataframes (eg, first dataframe with name and date, the second with name only) but you want to keep all rows (else if you join on only name for example, all date rows will be concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR 6TH MERGE (skip this cell if you did not do the first merge beforehand)\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_output\\merged_fmp_steph_manon_sarah_dicom_ecg.csv'\n",
    "id_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_output\\all_patients_fields.csv'\n",
    "ref_db_tounicode = True  # convert at loading the database to unicode? (If you get issues with accentuated characters or special characters in the final merged database, try to set this to True)\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_fmp_steph_manon_sarah_dicom_ecg_reports.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['', 'reports.'] # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "blankna = False  # blank null values when saving to csv? This improves readability but the dates and numbers can't be reformatted then.\n",
    "columns_order_first = [\"name\",\"name_alt6_cleanup\",\"MRI date (on mri paper) + Dicom Date Sync With CRS-R + Date of RMN + date_assess + StudyDate\",\"StudyDate\",\"MRI date (on mri paper) + Dicom Date Sync With CRS-R\",\"MRI date (on mri paper)\",\"fmpagg.CRSr::Date and subscores\",\"sarah.crs_subscore\",\"fmpagg.CRSr::Best Computed Outcome\",\"fmpagg.CRSr::Best Diagnosis\",\"fmpagg.Final diagnosis\",\"fmpagg.Dicom Diagnosis\",\"manon.Diagnostic CRS-R at date of RMN\",\"reports.final_diagnosis\",\"reports.best_clinical_paraclinical_diagnosis\",\"reports.diagnoses_clinical\",\"steph.CRS-R on same day\",\"manon.Diagnostic Final Comportemental\", \"manon.Diagnostic Final Para-clinique\", \"steph.MRI sedation\",\"manon.sedation epi \",\"manon.sedation struct\",\"fmpagg.MRI::Sedation EPI\",\"fmpagg.MRI::Sedation Given\",\"fmpagg.MRI::Sedation Structural\",\"fmpagg.Dicom Path Sedation\",\"reports.mri_sedation\",\"fmpagg.AcuteDicom\",\"\"\"steph.acute in comments means that document was in folder \"acute\", but it might not be at the time of MRI/PET\"\"\",\"reports.acute\",\"steph.gender\",\"fmpagg.Sexe\",\"reports.gender\",\"manon.Age\",\"reports.age\",\"fmpagg.Etiology\",\"fmpagg.Etiology specified.\",\"manon.Aetiology\",\"reports.accident_etiology\",\"steph.etio (from PET, still need to look in acute folder and whole dossier_hospi folders and hospital anamnese on omnipro)\",\"fmpagg.Date of Birth\",\"manon.DB\",\"reports.birthdate\",\"fmpagg.Date of Accident\",\"manon.Date of Injury\",\"dicom.ProtocolName\",\"dicom.SeriesDescription\",\"dicom.id\",\"dicom.match_{'ProtocolName': ['dti', 'repos']}\",\"dicom.match_{'ProtocolName': ['repos']}\",\"dicom.path\",\"ecg.ecg_infos\",\"ecg.ecg_types\",\"reports.epileptic\",\"steph.height\",\"steph.weight\",\"steph.comments MRI or PET\",\"fmpagg.Cause of Death\",\"fmpagg.Date of Death\",\"fmpagg.DiagnosisOutcome\",\"fmpagg.Diagnosis2Outcome\",\"fmpagg.Diagnosis3Outcome\",\"fmpagg.Diagnosis4Outcome\",\"fmpagg.DateOutcome\",\"fmpagg.Date2Outcome\",\"fmpagg.Date3Outcome\",\"fmpagg.Date4Outcome\",\"fmpagg.GOSEOutcome\",\"fmpagg.GOSE2Outcome\",\"fmpagg.GOSE3Outcome\",\"fmpagg.GOSE4Outcome\",\"fmpagg.Days random CRSr since accident\",\"fmpagg.Days scan since accident\",\"fmpagg.Diabetes\",\"fmpagg.Epilepsy\",\"fmpagg.Handedness\",\"fmpagg.PET::Arousal after injection\",\"fmpagg.PET::Ctac / Elac\",\"fmpagg.PET::Date of Assessment\",\"fmpagg.PET::Sedation\",\"fmpagg.PET::Weight Patient\",\"fmpagg.SeriesDescription\",\"fmpagg.ProtocolName\",\"fmpagg.Remarks\",\"fmpagg.deathdayssinceaccident\",\"fmpagg.deathdayssinceinsult\",\"manon.Comments\",\"manon.Date CRS-R\",\"manon.Diagnosis on admission\",\"manon.PET\",\"manon.Sedation + dose\",\"manon.rest\",\"manon.spatial\",\"manon.svs\",\"manon.tennis\",\"reports.accident_date\",\"reports.acquisition_date\",\"reports.acquisition_date_end\",\"reports.acquisition_minus_accident_days\",\"reports.admission_diagnosis\",\"reports.atypical_pattern\",\"reports.diagnoses_fmri\",\"reports.diagnoses_pet\",\"reports.had_mri\",\"reports.had_pet\",\"reports.mental_disorders\",\"reports.name_alt\",\"reports.nociception_report\",\"reports.ophtalmologic_report\",\"reports.report_date\",\"reports.report_lang\",\"reports.report_path\",\"reports.zolpidem_antirespondent\",\"reports.zolpidem_context\",\"reports.zolpidem_mention\",\"reports.zolpidem_respondent\",\"reports.zolpidem_tested\",\"steph.CRS-R BEST (unreliable, from dossier_hospi summary sheet, might miss some CRS-Rs, I noticed that myself)\",\"steph.CRS-R on day of PET scan\",\"steph.PET date (on PET paper)\",\"steph.PET sedation\", \"\"]  # put these columns first. If None, no reordering will be done (except that the key columns will be first).\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper) + Dicom Date Sync With CRS-R + Date of RMN + date_assess + StudyDate', 'datetime|%Y-%m-%d')])\n",
    "ref_db_keys = OrderedDict([('name', 'id')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = True  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n",
    "fillna_exclude = ['MRI date (on mri paper)', 'Dicom Date Sync With CRS-R', 'Date of RMN', 'date_assess', 'StudyDate']  # allow to exclude some columns from being filled when fillna=True, this is useful particularly for datetime columns\n",
    "join_on_shared_keys = True  # allow the merge on multi-columns to join on only the columns that are shared, this is useful when you want to groupby differently between dataframes (eg, first dataframe with name and date, the second with name only) but you want to keep all rows (else if you join on only name for example, all date rows will be concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load first database\n",
    "cid = pd.read_csv(id_db, sep=';', low_memory=False).dropna(how='all')\n",
    "if id_db_tounicode:  # convert to unicode if required (can fix issues with accentuated characters)\n",
    "    cid = df_to_unicode_fast(cid, progress_bar=True)\n",
    "if id_db_keys is not None:\n",
    "    print('IMPORTANT: Please check the date column (or any key column you used in your multikey) has the format you are expecting (because Excel does not show the true underlying format of some types, particularly dates).')\n",
    "cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second database\n",
    "# Note that the convention \"reference database\" has no meaning anymore, it comes from an old version of this notebook where both databases had a different role, now it is not the case, only the id database is used as a reference for the names\n",
    "cref = pd.read_csv(ref_db, sep=';', low_memory=False).dropna(how='all')\n",
    "if ref_db_tounicode:  # convert to unicode if required (can fix issues with accentuated characters)\n",
    "    cref = df_to_unicode_fast(cref, progress_bar=True)\n",
    "if ref_db_keys is not None:\n",
    "    print('IMPORTANT: Please check the date column (or any key column you used in your multikey) has the format you are expecting (because Excel does not show the true underlying format of some types, particularly dates).')\n",
    "cref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare prefix for columns renaming if rane_columns_per_csv is enabled\n",
    "# We use the first 3 characters of each path plus a dot\n",
    "# The user can also specify its own list of prefixes\n",
    "if rename_columns_per_csv is True:\n",
    "    prependcols = [os.path.basename(os.path.normpath(db))[:3]+'.' for db in [id_db, ref_db]]\n",
    "elif isinstance(rename_columns_per_csv, list) and len(rename_columns_per_csv) == 2:\n",
    "    prependcols = rename_columns_per_csv\n",
    "else:\n",
    "    prependcols = None\n",
    "prependcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare key columns if using multiple columns as keys for the merge\n",
    "if id_db_keys and ref_db_keys:\n",
    "    keycol = [id_db_keys, ref_db_keys]\n",
    "else:\n",
    "    keycol = shared_key_column\n",
    "keycol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge both databases if name matches (here we extract the names/indices where they match)\n",
    "cmerge, cfinal = merge_two_df(cid, cref, col=keycol, mode=0,\n",
    "                              dist_threshold=dist_threshold,\n",
    "                              dist_words_threshold=dist_words_threshold,\n",
    "                              skip_sanity=True, keep_nulls=True,\n",
    "                              returnmerged=True, prependcols=prependcols,\n",
    "                              fillna=fillna, fillna_exclude=fillna_exclude,\n",
    "                              join_on_shared_keys=join_on_shared_keys,\n",
    "                              indicator=pdmerge_indicator, validate=pdmerge_validate)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the merge mapping\n",
    "cmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the merged result (unified database)\n",
    "cfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder so that the first columns are always the key columns\n",
    "if isinstance(keycol, list):\n",
    "    # Deduplicate the key columns list (to avoid duplicating columns!)\n",
    "    keycol_unique = []\n",
    "    for kcol in keycol:\n",
    "        for colname, coltype in kcol.items():\n",
    "            if colname not in keycol_unique:\n",
    "                keycol_unique.append(colname)\n",
    "    # Reorder\n",
    "    cfinal = reorder_cols_df(cfinal, keycol_unique)\n",
    "else:\n",
    "    # Only one key column, reorder according to it\n",
    "    cfinal = reorder_cols_df(cfinal, [keycol])\n",
    "cfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merge mapping and unified database as csv files\n",
    "cfinal_unicode = df_to_unicode_fast(cfinal)\n",
    "cmerge_unicode = df_to_unicode_fast(cmerge)\n",
    "if save_df_as_csv(cfinal_unicode, out_db, fields_order=columns_order_first if columns_order_first is not None else False, csv_order_by='name', blankna=blankna, date_format='%Y-%m-%d') and \\\n",
    "    save_df_as_csv(cmerge_unicode, out_db[:-4]+'_mapping.csv', fields_order=columns_order_first if columns_order_first is not None else False, csv_order_by='name', blankna=blankna):\n",
    "    print('Merged database successfully saved in %s and %s!' % (out_db, out_db[:-4]+'_mapping.csv'))\n",
    "else:\n",
    "    print('ERROR: the merged database could not be saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
