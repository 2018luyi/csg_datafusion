{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Databases Merger\n",
    "By Stephen Karl Larroque @ Coma Science Group, GIGA Research, University of Liege\n",
    "Creation date: 2018-05-27\n",
    "License: MIT\n",
    "v1.3.6\n",
    "2018-2019\n",
    "\n",
    "DESCRIPTION:\n",
    "Generic tool to merge two CSV databases based on the subject's name (hence expecting a column 'name' in each csv file).\n",
    "This script will take care of fuzzy matching names and append all columns of each csv file, hence centralizing all informations into one file.\n",
    "\n",
    "Note: in case of multiple names/lines matching, they will all be concatenated into a single line: if one name in one of the two databases match multiple names/lines of the second database, then the second databases lines will be concatenated into one. In the opposite case (second database's name match multiple names in first database), the same holds.\n",
    "\n",
    "INSTALL NOTE:\n",
    "You need to pip install pandas before launching this script.\n",
    "Tested on Python 2.7.13\n",
    "\n",
    "USAGE:\n",
    "\n",
    "TODO:\n",
    "* Nothing here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcefully autoreload all python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUX FUNCTIONS\n",
    "\n",
    "import os, sys\n",
    "\n",
    "cur_path = os.path.realpath('.')\n",
    "sys.path.append(os.path.join(cur_path, 'csg_fileutil_libs'))  # for unidecode and cleanup_name, because it does not support relative paths (yet?)\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict\n",
    "from csg_fileutil_libs.aux_funcs import save_df_as_csv, _tqdm, merge_two_df, df_remap_names, concat_vals, df_literal_eval, df_to_unicode_fast, reorder_cols_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_original\\patients-sedation-2018-checked-by-Stephen-from-archives_v7_2018-10-18_full-names-merged.csv'\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_output\\fmp_db_subjects_aggregated.csv_etiosedatfixed_dicomsdatediag_dicompathsedat.csv_acute.csv'\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_db.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['steph.', 'fmpagg.']  # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "#id_db_keys = None\n",
    "#ref_db_keys = None\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper)', 'datetime|%d/%m/%Y')])\n",
    "ref_db_keys = OrderedDict([('name', 'id'), ('Dicom Date', 'datetime|%Y-%m-%d')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = True  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR 2ND MERGE (skip this cell if you did not do the first merge beforehand)\n",
    "\n",
    "# First (ID) database to merge (both need to have a column 'name'). The merged 'name' column will use the names from this database.\n",
    "id_db = r'databases_output\\merged_db_1.csv'\n",
    "# Second (reference) database to merge. The names will be added as a new column 'name_altx'.\n",
    "ref_db = r'databases_original\\manon_Database_MRI_patients.csv'\n",
    "# Output database with the merge results\n",
    "out_db = r'databases_output\\merged_db.csv'\n",
    "\n",
    "# Similarity search parameters (of names in both databases)\n",
    "dist_threshold = 0.2 # character distance (normalized on 1 over the total number of characters = jaccard distance), lower is more similar, default: 0.2\n",
    "dist_words_threshold = 0.4 # words distance (normalized idem but on number of words), default: 0.2\n",
    "keep_lastname_only = False # keep only the lastname? (supposed to be the first word) - this can enhance the matching if there are too many false positives, particularly if one database only include the last name but the other one has the full name\n",
    "\n",
    "# Additional options\n",
    "rename_columns_per_csv = ['', 'manon.'] # rename each column by prepending the csv file from where the column comes from. True will use the first 3 letters from the filename, or a list of 2 string prefixes can be provided, or False to disable renaming\n",
    "#rename_columns_per_csv = False\n",
    "pdmerge_indicator = False  # pandas.merge() option, if True, a new column 'x_merge' will be created for every columns, summarizing from what original database the info was merged from\n",
    "pdmerge_validate = None  # pandas.merge() option, allows to ensure that the mapping is unique, for example with '1:1'. Can be: '1:1', '1:m', 'm:1', 'm:m'\n",
    "\n",
    "# Multi-columns merging\n",
    "# keys to use for the merge: by default will only use the 'name' column, but can merge on multiple columns and with different types: 'id' or 'datetime' are supported\n",
    "# the order of the columns must be the same, since we will not use the column names: the id's database first column must match the same type as the ref's database first column, etc for all subsequent columns\n",
    "# format is: an OrderedDict with the column_name: column_type for each item\n",
    "id_db_keys = OrderedDict([('name', 'id'), ('MRI date (on mri paper) + Dicom Date', 'datetime|%Y-%m-%d')])\n",
    "ref_db_keys = OrderedDict([('name', 'id'), ('Date of RMN', 'datetime|%d/%m/%Y')])\n",
    "shared_key_column = 'name'  # in case you set ref_db_keys and id_db_keys to None (to disable multi-columns merging), you can specify here the name of the single column that both databases share, and on which the merge will be done\n",
    "fillna = True  # if merging on multiple key columns, if fillna=True this will try to fill nan fields from other filled fields from the same subject, eg: subject A has 2 sessions, one with lots of infos, second session mostly empty, with fillna=True the second session will get all missing infos copied over from the first (except for the key columns of course)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load first database\n",
    "cid = pd.read_csv(id_db, sep=';').dropna(how='all')\n",
    "cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second database\n",
    "cref = pd.read_csv(ref_db, sep=';').dropna(how='all')\n",
    "cref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare prefix for columns renaming if rane_columns_per_csv is enabled\n",
    "# We use the first 3 characters of each path plus a dot\n",
    "# The user can also specify its own list of prefixes\n",
    "if rename_columns_per_csv is True:\n",
    "    prependcols = [os.path.basename(os.path.normpath(db))[:3]+'.' for db in [id_db, ref_db]]\n",
    "elif isinstance(rename_columns_per_csv, list) and len(rename_columns_per_csv) == 2:\n",
    "    prependcols = rename_columns_per_csv\n",
    "else:\n",
    "    prependcols = None\n",
    "prependcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare key columns if using multiple columns as keys for the merge\n",
    "if id_db_keys and ref_db_keys:\n",
    "    keycol = [id_db_keys, ref_db_keys]\n",
    "else:\n",
    "    keycol = shared_key_column\n",
    "keycol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge both databases if name matches (here we extract the names/indices where they match)\n",
    "cmerge, cfinal = merge_two_df(cid, cref, col=keycol, mode=0,\n",
    "                              dist_threshold=dist_threshold,\n",
    "                              dist_words_threshold=dist_words_threshold,\n",
    "                              skip_sanity=True, keep_nulls=True,\n",
    "                              returnmerged=True, prependcols=prependcols,\n",
    "                              fillna=fillna,\n",
    "                              indicator=pdmerge_indicator, validate=pdmerge_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the merge mapping\n",
    "cmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the merged result (unified database)\n",
    "cfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder so that the first columns are always the key columns\n",
    "if isinstance(keycol, list):\n",
    "    # Deduplicate the key columns list (to avoid duplicating columns!)\n",
    "    keycol_unique = []\n",
    "    for kcol in keycol:\n",
    "        for colname, coltype in kcol.items():\n",
    "            if colname not in keycol_unique:\n",
    "                keycol_unique.append(colname)\n",
    "    # Reorder\n",
    "    cfinal = reorder_cols_df(cfinal, keycol_unique)\n",
    "else:\n",
    "    # Only one key column, reorder according to it\n",
    "    cfinal = reorder_cols_df(cfinal, keycol)\n",
    "cfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merge mapping and unified database as csv files\n",
    "cfinal_unicode = df_to_unicode_fast(cfinal)\n",
    "cmerge_unicode = df_to_unicode_fast(cmerge)\n",
    "if save_df_as_csv(cfinal_unicode, out_db, fields_order=list(cfinal_unicode.columns), csv_order_by='name', blankna=True) and \\\n",
    "    save_df_as_csv(cmerge_unicode, out_db[:-4]+'_mapping.csv', fields_order=list(cmerge_unicode.columns), csv_order_by='name', blankna=True):\n",
    "    print('Merged database successfully saved in %s and %s!' % (out_db, out_db[:-4]+'_mapping.csv'))\n",
    "else:\n",
    "    print('ERROR: the merged database could not be saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
