{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics (under work)\n",
    "v0.2.0\n",
    "By Stephen Karl Larroque\n",
    "License: All rights reserved (in the future will be converted to MIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcefully autoreload all python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUX FUNCTIONS\n",
    "\n",
    "import os, sys\n",
    "\n",
    "cur_path = os.path.realpath('.')\n",
    "sys.path.append(os.path.join(cur_path, 'csg_fileutil_libs'))  # for unidecode and cleanup_name, because it does not support relative paths (yet?)\n",
    "\n",
    "import re\n",
    "\n",
    "from csg_fileutil_libs.aux_funcs import save_df_as_csv, _tqdm, compute_best_diag, reorder_cols_df, find_columns_matching, cleanup_name, replace_buggy_accents, convert_to_datetype, df_drop_duplicated_index, df_to_unicode, df_to_unicode_fast, cleanup_name_df, df_literal_eval, compute_best_diag, df_unify, df_translate, df_filter_nan_str, concat_vals_unique, reorder_cols_df, sort_and_deduplicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice plots!\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# Unified database, not yet postprocessed\n",
    "unified_csv = r'databases_output\\merged_fmp_steph_manon_sarah_dicom_ecg_reports_unifiedall_nifti.csv'\n",
    "unifiedpersubj_csv = r'databases_output\\merged_fmp_steph_manon_sarah_dicom_ecg_reports_unifiedall.csv'\n",
    "output_dir = r'databases_output'\n",
    "\n",
    "# Hide null values in plots?\n",
    "plot_hide_nan = True\n",
    "\n",
    "diagorder_doc = ['', 'na', 'impossible', 'braindead', 'coma', 'vs/uws', 'mcs', 'mcs-', 'mcs+', 'srmcs', 'emcs', 'lis', 'lis_incomplete', 'partial lis']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## PREPARE DATASET (AND ONLYDOC DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the csv dbs as dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cf_unified = pd.read_csv(unified_csv, sep=';', low_memory=False).dropna(axis=0, how='all').fillna('')  # drop empty lines\n",
    "cf_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified['unified.diagnosis_best'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to keep only doc patients (susceptible to being sedated)\n",
    "cf_unified_onlydoc = cf_unified[cf_unified['unified.diagnosis_best'].isin(['vs/uws', 'mcs', 'mcs+', 'mcs-', 'emcs', 'srmcs', 'coma', 'lis', 'lis_incomplete', 'partial lis', 'conflict', 'braindead'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by name\n",
    "cf_unified_onlydoc_byname = cf_unified_onlydoc.groupby('name').agg(concat_vals_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check diagnoses count is fine (sanity check)\n",
    "cf_unified_onlydoc_byname.reset_index().loc[:, ['name', 'unified.diagnoses_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_csv(cf_unified_onlydoc_byname, 'onlydoc.csv', fields_order=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## FOR MURIELLE (MRI SEDATION STATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bynamecounts.txt', 'w') as f:\n",
    "    f.write(cf_unified_onlydoc_byname.count().to_string())\n",
    "cf_unified_onlydoc_byname.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc[cf_unified_onlydoc['nifti.func OK'].isin(['O', 'M', 'M2', 'N'])].groupby('name').agg(concat_vals_unique).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc[cf_unified_onlydoc['nifti.struct OK (for fmri)'].isin(['O', 'M', 'M2', 'N', 'W'])].groupby('name').agg(concat_vals_unique).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregate per MRI sessions\n",
    "cf_unified_onlydoc_sess = cf_unified_onlydoc[~cf_unified_onlydoc['StudyDate'].isnull() & (cf_unified_onlydoc['StudyDate'] != '')].groupby(['name', 'StudyDate']).agg(concat_vals_unique)\n",
    "cf_unified_onlydoc_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc_sess[~cf_unified_onlydoc_sess['nifti.func OK'].isin(['X', ''])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc_sess[~cf_unified_onlydoc_sess['nifti.struct OK (for fmri)'].isin(['X', ''])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveepisedat(cf, appendtext=''):\n",
    "    a = cf['unified.episedation']\n",
    "    b = a.astype('str').value_counts()\n",
    "    c = b.to_frame().reset_index().rename(columns={'index': 'sedation', 'unified.episedation': 'count'})\n",
    "    df_to_unicode_fast(c).to_excel(unified_csv[:-4] + '_episedationcount%s.xls' % appendtext)\n",
    "    return True\n",
    "saveepisedat(cf_unified_onlydoc_sess, '_persess')\n",
    "saveepisedat(cf_unified_onlydoc_byname, '_persubject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "#toplot = cf_unified_perdiag[cf_unified_perdiag['unified.diagnosis_worst'] == diag]['unified.diagnosis_best'].astype('str').value_counts(dropna=plot_hide_nan)\n",
    "cf_unified_onlydoc_byname['unified.etiology'].value_counts().plot(fig=fig, kind='pie', title='Etiology of DOC patients\\n%i patients' % (cf_unified_onlydoc_byname.shape[0]), autopct='%.1f%%', figsize=(15,15))\n",
    "plt.axis('off')\n",
    "fig.savefig(os.path.join(output_dir, 'fig_docetio.png'), bbox_inches='tight', dpi=600)\n",
    "with open(os.path.join(output_dir, 'fig_docetio.txt'), 'w') as f:\n",
    "    f.write(cf_unified_onlydoc_byname['unified.etiology'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "cf_unified_onlydoc_sess.loc[cf_unified_onlydoc_sess['unified.diagnosis_best'] == 'srmcs', 'unified.diagnosis_best'] = 'mcs+'\n",
    "for diag in cf_unified_onlydoc_sess['unified.diagnosis_best'].unique():\n",
    "    fig = plt.figure()\n",
    "    toplot = cf_unified_onlydoc_sess.loc[cf_unified_onlydoc_sess['unified.diagnosis_best'] == diag, 'unified.episedation']\n",
    "    toplot.value_counts().plot(fig=fig, kind='pie', title='Sedation for diag %s\\n%i sessions' % (diag.replace('/', '-'), toplot.shape[0]), autopct='%.1f%%', figsize=(15,15))\n",
    "    plt.axis('off')\n",
    "    fig.savefig(os.path.join(output_dir, 'fig_sedat_%s.png' % diag.replace('/', '-')), bbox_inches='tight', dpi=600)\n",
    "    with codecs.open(os.path.join(output_dir, 'fig_sedat_%s.txt' % diag.replace('/', '-')), 'w', 'utf-8-sig') as f:\n",
    "        f.write(toplot.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "## MARKOV CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the csv dbs as dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cf_unifiedsubj = pd.read_csv(unifiedpersubj_csv, sep=';', low_memory=False).dropna(axis=0, how='all').fillna('')  # drop empty lines\n",
    "cf_unifiedsubj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unifiedsubj['unified.diagnosis_best'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to keep only doc patients (susceptible to being sedated)\n",
    "cf_unifiedsubj_onlydoc = cf_unifiedsubj[cf_unifiedsubj['unified.diagnosis_best'].isin(['vs/uws', 'mcs', 'mcs+', 'mcs-', 'emcs', 'srmcs', 'coma', 'lis', 'lis_incomplete', 'partial lis', 'conflict', 'braindead'])]\n",
    "cf_unifiedsubj_onlydoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc_byname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc_byname.reset_index().loc[:, ['name', 'unified.diagnoses_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_columns_matching(cf_unified_onlydoc_byname, ['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract max crsr count\n",
    "cf_unified_onlydoc_byname['unified.diagnoses_count'] = cf_unified_onlydoc_byname['unified.diagnoses_count'].apply(lambda x: max(x) if isinstance(x, list) else x)\n",
    "cf_unified_onlydoc_byname['unified.diagnoses_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only patients with at least 2 CRS-Rs (else can't see any transition)\n",
    "cf_unified_onlydoc_byname_min2diag = cf_unified_onlydoc_byname.loc[cf_unified_onlydoc_byname['unified.diagnoses_count'] >= 2, :]\n",
    "# Drop the 'test test' patient\n",
    "cf_unified_onlydoc_byname_min2diag.drop('test test', inplace=True)\n",
    "# Show\n",
    "cf_unified_onlydoc_byname_min2diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc_byname_min2diag['unified.diagnoses_count'].plot(kind='hist', bins=max(cf_unified_onlydoc_byname_min2diag['unified.diagnoses_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cases where there are multiple best or worst diagnoses (which should not happen)\n",
    "conflictdiags = cf_unified_onlydoc_byname_min2diag.loc[cf_unified_onlydoc_byname_min2diag['unified.diagnosis_worst'].apply(lambda x: isinstance(x, list)), :].index\n",
    "cf_unified_onlydoc_byname_min2diag.loc[conflictdiags, find_columns_matching(cf_unified_onlydoc_byname_min2diag, 'unified')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix cases where there are multiple best/worst diagnoses, by selecting the best/worst diagnosis respectively\n",
    "\n",
    "# Order diagnoses using Pandas discrete categories, so that we can easily grade the maximum and minimum diagnoses\n",
    "cf_unified_onlydoc_byname_min2diag.loc[:, 'unified.diagnosis_worst'] = cf_unified_onlydoc_byname_min2diag['unified.diagnosis_worst'].apply(lambda x: compute_best_diag(x, diag_order=diagorder_doc, persubject=None).min() if not isinstance(x, str) else x)\n",
    "cf_unified_onlydoc_byname_min2diag.loc[:, 'unified.diagnosis_best'] = cf_unified_onlydoc_byname_min2diag['unified.diagnosis_best'].apply(lambda x: compute_best_diag(x, diag_order=diagorder_doc, persubject=None).max() if not isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check if the previous docs with conflicting diagnoses are now ok\n",
    "cf_unified_onlydoc_byname_min2diag.loc[conflictdiags, find_columns_matching(cf_unified_onlydoc_byname_min2diag, 'unified')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = cf_unified_onlydoc_byname_min2diag.loc[cf_unified_onlydoc_byname_min2diag['unified.diagnosis_worst'].apply(lambda x: isinstance(x, list)), find_columns_matching(cf_unified_onlydoc_byname_min2diag, 'unified')]\n",
    "# correct:\n",
    "#print(a['unified.diagnosis_worst'].apply(lambda x: compute_best_diag(x, diag_order=['', 'na', 'impossible'] + diagorder_doc + ['lis'], persubject=None).min()))\n",
    "#print(a['unified.diagnosis_worst'].apply(lambda x: compute_best_diag(x, diag_order=['', 'na', 'impossible'] + diagorder_doc + ['lis'], persubject=None).max()))\n",
    "# wrong:\n",
    "#print(a['unified.diagnosis_worst'].apply(lambda x: min(compute_best_diag(x, diag_order=['', 'na', 'impossible'] + diagorder_doc + ['lis'], persubject=None)))\n",
    "#print(a['unified.diagnosis_worst'].apply(lambda x: max(compute_best_diag(x, diag_order=['', 'na', 'impossible'] + diagorder_doc + ['lis'], persubject=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valsorder = ['AAA', 'BBBBBBBBB', 'CCCCC', 'DD', 'EEE']\n",
    "#s = pd.Series(valsorder[1:4])\n",
    "#s = s.astype(pd.api.types.CategoricalDtype(categories=valsorder, ordered=True))\n",
    "#min(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_transition_matrix(df, col1, col2, proba=True):\n",
    "    \"\"\"proba == True to return probabilities, or False to return counts\"\"\"\n",
    "    try:\n",
    "        tmat = pd.DataFrame(0, index=df[col1].unique(), columns=df[col2].unique())\n",
    "    except TypeError as exc:\n",
    "        tmat = pd.DataFrame(0, index=df[col1].astype('str').unique(), columns=df[col2].astype('str').unique())\n",
    "    for idx, row in df.iterrows():\n",
    "        tmat.loc[row[col1], row[col2]] += 1\n",
    "    if proba:\n",
    "        tmat = tmat.apply(lambda x: x / x.sum(), axis=1)\n",
    "    return tmat\n",
    "\n",
    "tmat = calc_transition_matrix(cf_unified_onlydoc_byname_min2diag, 'unified.diagnosis_worst', 'unified.diagnosis_best', proba=True)\n",
    "tmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(tmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns and indices\n",
    "tmat = tmat.loc[:, [x for x in diagorder_doc if x in tmat.columns]]  # easiest way: get the whole ordered list and filter it through the existing columns\n",
    "tmat = tmat.loc[[x for x in diagorder_doc if x in tmat.index], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMITATIONS OF THIS STUDY:\n",
    "# * does not account for temporality between worst and best diagnosis, thus worst diagnosis may well be an evolution happening later than the best diagnosis. Here we show the possible transitions between both, should be considered bidirectional. Thus interpretation is not necessarily of an evolution but a possible transition between both states.\n",
    "# we could change that but what criterion should we use? And what timeframe, if it's a daytoday fluctuation, should we consider this is ...? Or simply restrict analysis to all crs-r timeframe under 3 months, so we consider it's not evolution, only fluctuation or short term evolution.\n",
    "\n",
    "# RESULTS\n",
    "#* most change diag, dont be fooled by the heatmap, so this and graph are bad viz, they dont show the main result. Problem with heatmap is the colors: how do you add the colors to know that in fact where it's most salient isn't the majority of the changes?\n",
    "#* SOLUTION: add 3 columns: worsening, no change and improvement, and these will be the sum of enhancement vs no change vs worsening. Simple to calculate: same position in x and y = no change, below position in columns compared to index = worsening, opposite is improvement.\n",
    "#* srmcs 50% chance change to emcs. we question the pertinence of requiring 2 consecutive fulfillment of the tasks\n",
    "\n",
    "# TODO:\n",
    "#* account for bidirectionality by detecting order of worst and best diag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotheatmap(df):\n",
    "    df[df==0] = float('NaN')  # make 0 values blank\n",
    "    plt.pcolor(df, cmap=plt.get_cmap('viridis'))\n",
    "    plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
    "    plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\n",
    "    plt.show()\n",
    "plotheatmap(tmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division  # Only for how I'm writing the transition matrix\n",
    "import networkx as nx  # For the magic\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "\n",
    "# Install pydot and graphviz beforehand, and change the path below on Windows to your graphviz folder\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "# and the following code block is not needed\n",
    "# but we want to see which module is used and\n",
    "# if and why it fails\n",
    "try:\n",
    "    import pygraphviz\n",
    "    from networkx.drawing.nx_agraph import write_dot\n",
    "    print(\"using package pygraphviz\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import pydot\n",
    "        from networkx.drawing.nx_pydot import write_dot, to_pydot\n",
    "        print(\"using package pydot\")\n",
    "    except ImportError:\n",
    "        print()\n",
    "        print(\"Both pygraphviz and pydot were not found \")\n",
    "        print(\"see  https://networkx.github.io/documentation/latest/reference/drawing.html\")\n",
    "        print()\n",
    "        raise\n",
    "\n",
    "def transition_to_graph(df):\n",
    "    # Adapted from https://vknight.org/unpeudemath/code/2015/11/15/Visualising-markov-chains.html\n",
    "    G = nx.MultiDiGraph(directed=True)\n",
    "    labels={}\n",
    "    edge_labels={}\n",
    "\n",
    "    for state1 in df.index:\n",
    "        for state2 in df.columns:\n",
    "            weight = df.loc[state1, state2]\n",
    "            if weight > 0:\n",
    "                G.add_edge(state1,\n",
    "                           state2,\n",
    "                           weight=weight,\n",
    "                           penwidth=weight*10,\n",
    "                           label=\"{:.02f}\".format(weight))\n",
    "                edge_labels[(state1, state2)] = label=\"{:.02f}\".format(weight)\n",
    "    return G\n",
    "\n",
    "def plot_transition_graph(G, pos=None):\n",
    "    # https://stackoverflow.com/questions/20133479/how-to-draw-directed-graphs-using-networkx-in-python\n",
    "    plt.figure(figsize=(14,7))\n",
    "    #node_size = 200\n",
    "    #pos = {state:list(state) for state in states}\n",
    "    #nx.draw_networkx_edges(G,pos,width=1.0,alpha=0.5)\n",
    "    #nx.draw_networkx_labels(G, pos, font_weight=2)\n",
    "    options = {\n",
    "        'node_color': 'cyan',\n",
    "        'node_size': 2000,\n",
    "        'width': 1,\n",
    "        'arrowstyle': '-|>',\n",
    "        'arrowsize': 30,\n",
    "    }\n",
    "    if pos is None:\n",
    "        # Get the layout defined manually in G\n",
    "        pos = nx.get_node_attributes(G,'pos')\n",
    "        if not pos:\n",
    "            # Else calculate a layout automatically\n",
    "            #pos = nx.nx_pydot.graphviz_layout(G, prog='neato')\n",
    "            pos = nx.drawing.layout.spectral_layout(G)\n",
    "    nx.draw(G, pos, arrows=True, with_labels=True, **options)\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_transition_graph2(G, pos=None):\n",
    "    # add graphviz layout options (see https://stackoverflow.com/a/39662097)\n",
    "    G.graph['edge'] = {'arrowsize': '0.6', 'splines': 'curved', 'rankdir':'LR'}\n",
    "    G.graph['graph'] = {'scale': '3'}\n",
    "\n",
    "    # adding attributes to edges in multigraphs is more complicated but see\n",
    "    # https://stackoverflow.com/a/26694158\n",
    "    #G[1][1][0]['color']='red'\n",
    "\n",
    "    # From: https://stackoverflow.com/questions/4596962/display-graph-without-saving-using-pydot\n",
    "    # convert from networkx -> pydot\n",
    "    pydot_graph = to_pydot(G)\n",
    "\n",
    "    # render pydot by calling dot, no file saved to disk\n",
    "    png_str = pydot_graph.create_png(prog='dot') # can change to dot or twopi, but not neato because the latter is only for non directed graphs\n",
    "\n",
    "    # treat the dot output string as an image file\n",
    "    sio = StringIO()\n",
    "    sio.write(png_str)\n",
    "    sio.seek(0)\n",
    "    img = mpimg.imread(sio)\n",
    "\n",
    "    # plot the image\n",
    "    plt.figure(figsize=(40,15))\n",
    "    imgplot = plt.imshow(img, aspect='equal')\n",
    "    plt.axis('off')\n",
    "    plt.show(block=False)\n",
    "\n",
    "from cStringIO import StringIO\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "G = transition_to_graph(tmat)\n",
    "# set position manually\n",
    "#for i, n in enumerate(G):\n",
    "#    G.node[n]['pos'] = '\"%d,%d\"' % (i, 1)\n",
    "write_dot(G, 'mc.dot')\n",
    "plot_transition_graph2(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from networkx -> pydot\n",
    "pydot_graph = to_pydot(G)\n",
    "pydot_graph.set_concentrate(True)\n",
    "pydot_graph.set_layout('dot')\n",
    "pydot_graph.set_dpi(300)\n",
    "pydot_graph.set_pack(True)\n",
    "#pydot_graph.set_rank('same')\n",
    "pydot_graph.set_splines('line')\n",
    "\n",
    "# render pydot by calling dot, no file saved to disk\n",
    "png_str = pydot_graph.create_png(prog='dot') # can change to dot or twopi, but not neato because the latter is only for non directed graphs\n",
    "\n",
    "# treat the dot output string as an image file\n",
    "sio = StringIO()\n",
    "sio.write(png_str)\n",
    "sio.seek(0)\n",
    "img = mpimg.imread(sio)\n",
    "\n",
    "# plot the image\n",
    "plt.figure(figsize=(40,15))\n",
    "imgplot = plt.imshow(img, aspect='equal')\n",
    "plt.axis('off')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_unified_onlydoc_byname_min2diag['unified.diagnosis_best'].astype('str').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_columns_matching(cf_unified_onlydoc_byname_min2diag, 'unified')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
